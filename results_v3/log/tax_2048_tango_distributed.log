WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.
Error dist count [274, 698, 0, 0, 0, 201, 600, 401, 200, 200, 3, 188, 200, 0, 200]
Original error count [274 698   0   0   0 201 600 401 200 200   3 188 200   0 200]
2022-08-04 10:16:05,066 INFO spark.SparkContext: Running Spark version 3.2.0
2022-08-04 10:16:05,163 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-08-04 10:16:05,305 INFO resource.ResourceUtils: ==============================================================
2022-08-04 10:16:05,305 INFO resource.ResourceUtils: No custom resources configured for spark.driver.
2022-08-04 10:16:05,305 INFO resource.ResourceUtils: ==============================================================
2022-08-04 10:16:05,306 INFO spark.SparkContext: Submitted application: DataGenerator_dirty_tax_2048.0
2022-08-04 10:16:05,334 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 102400, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-08-04 10:16:05,360 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks per executor
2022-08-04 10:16:05,362 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0
2022-08-04 10:16:05,453 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-04 10:16:05,453 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-04 10:16:05,454 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-04 10:16:05,454 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-04 10:16:05,455 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-04 10:16:05,786 INFO util.Utils: Successfully started service 'sparkDriver' on port 45167.
2022-08-04 10:16:05,821 INFO spark.SparkEnv: Registering MapOutputTracker
2022-08-04 10:16:05,861 INFO spark.SparkEnv: Registering BlockManagerMaster
2022-08-04 10:16:05,884 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-08-04 10:16:05,884 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-08-04 10:16:05,929 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2022-08-04 10:16:05,958 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-fb98d821-097e-4636-beeb-dfc56de63a0b
2022-08-04 10:16:05,996 INFO memory.MemoryStore: MemoryStore started with capacity 434.4 MiB
2022-08-04 10:16:06,044 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2022-08-04 10:16:06,183 INFO util.log: Logging initialized @11406ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-08-04 10:16:06,260 INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-Ubuntu-0ubuntu1.20.04
2022-08-04 10:16:06,283 INFO server.Server: Started @11507ms
2022-08-04 10:16:06,329 INFO server.AbstractConnector: Started ServerConnector@63043f01{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-08-04 10:16:06,329 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2022-08-04 10:16:06,358 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@12fa8862{/jobs,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,361 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4c3db4c2{/jobs/json,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,363 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@23d6c3b9{/jobs/job,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,366 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5679f888{/jobs/job/json,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,367 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20fe3977{/stages,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,369 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26c4aaac{/stages/json,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,370 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7773af6e{/stages/stage,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,372 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2bfc133c{/stages/stage/json,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,373 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@570f4012{/stages/pool,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,375 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74dc353f{/stages/pool/json,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,376 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@64e44a5f{/storage,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,377 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5bfc61a8{/storage/json,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,378 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6052fdff{/storage/rdd,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,379 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70abb8f1{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,380 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@361c073f{/environment,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,381 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@406ff82d{/environment/json,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,382 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@62819ade{/executors,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,383 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@45eca2d4{/executors/json,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,384 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d358b7a{/executors/threadDump,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,387 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3b9d2667{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,399 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1c0d8860{/static,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,400 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@31cc2d5f{/,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,401 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1c14466c{/api,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,402 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a50d305{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,404 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@557f33ee{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-08-04 10:16:06,406 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://tango.dm.isds.tugraz.at:4040
2022-08-04 10:16:06,775 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at charlie.dm.isds.tugraz.at/129.27.206.4:8032
2022-08-04 10:16:07,003 INFO yarn.Client: Requesting a new application from cluster with 9 NodeManagers
2022-08-04 10:16:07,513 INFO conf.Configuration: resource-types.xml not found
2022-08-04 10:16:07,514 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2022-08-04 10:16:07,526 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (122880 MB per container)
2022-08-04 10:16:07,526 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
2022-08-04 10:16:07,527 INFO yarn.Client: Setting up container launch context for our AM
2022-08-04 10:16:07,528 INFO yarn.Client: Setting up the launch environment for our AM container
2022-08-04 10:16:07,534 INFO yarn.Client: Preparing resources for our AM container
2022-08-04 10:16:08,138 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2022-08-04 10:16:10,446 INFO yarn.Client: Uploading resource file:/tmp/spark-22e9994b-2f4c-48fd-82dc-0285f1bc1fbf/__spark_libs__11774102371472312998.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0209/__spark_libs__11774102371472312998.zip
2022-08-04 10:16:13,247 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/pyspark.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0209/pyspark.zip
2022-08-04 10:16:14,342 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/py4j-0.10.9.2-src.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0209/py4j-0.10.9.2-src.zip
2022-08-04 10:16:15,589 INFO yarn.Client: Uploading resource file:/tmp/spark-22e9994b-2f4c-48fd-82dc-0285f1bc1fbf/__spark_conf__700467314913654782.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0209/__spark_conf__.zip
2022-08-04 10:16:16,804 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-04 10:16:16,805 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-04 10:16:16,805 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-04 10:16:16,805 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-04 10:16:16,805 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-04 10:16:16,827 INFO yarn.Client: Submitting application application_1659444800769_0209 to ResourceManager
2022-08-04 10:16:16,867 INFO impl.YarnClientImpl: Submitted application application_1659444800769_0209
2022-08-04 10:16:17,870 INFO yarn.Client: Application report for application_1659444800769_0209 (state: ACCEPTED)
2022-08-04 10:16:17,873 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659600976841
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0209/
	 user: oovcharenko
2022-08-04 10:16:18,875 INFO yarn.Client: Application report for application_1659444800769_0209 (state: ACCEPTED)
2022-08-04 10:16:19,876 INFO yarn.Client: Application report for application_1659444800769_0209 (state: ACCEPTED)
2022-08-04 10:16:20,878 INFO yarn.Client: Application report for application_1659444800769_0209 (state: ACCEPTED)
2022-08-04 10:16:21,880 INFO yarn.Client: Application report for application_1659444800769_0209 (state: ACCEPTED)
2022-08-04 10:16:22,882 INFO yarn.Client: Application report for application_1659444800769_0209 (state: ACCEPTED)
2022-08-04 10:16:23,375 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> charlie.dm.isds.tugraz.at, PROXY_URI_BASES -> http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0209), /proxy/application_1659444800769_0209
2022-08-04 10:16:23,883 INFO yarn.Client: Application report for application_1659444800769_0209 (state: RUNNING)
2022-08-04 10:16:23,884 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 129.27.206.24
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659600976841
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0209/
	 user: oovcharenko
2022-08-04 10:16:23,885 INFO cluster.YarnClientSchedulerBackend: Application application_1659444800769_0209 has started running.
2022-08-04 10:16:23,897 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38701.
2022-08-04 10:16:23,897 INFO netty.NettyBlockTransferService: Server created on tango.dm.isds.tugraz.at:38701
2022-08-04 10:16:23,899 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-08-04 10:16:23,906 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 38701, None)
2022-08-04 10:16:23,911 INFO storage.BlockManagerMasterEndpoint: Registering block manager tango.dm.isds.tugraz.at:38701 with 434.4 MiB RAM, BlockManagerId(driver, tango.dm.isds.tugraz.at, 38701, None)
2022-08-04 10:16:23,914 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 38701, None)
2022-08-04 10:16:23,916 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, tango.dm.isds.tugraz.at, 38701, None)
2022-08-04 10:16:24,120 INFO ui.ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 10:16:24,123 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@22a6c066{/metrics/json,null,AVAILABLE,@Spark}
2022-08-04 10:16:24,260 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
2022-08-04 10:16:30,436 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.14:53104) with ID 1,  ResourceProfileId 0
2022-08-04 10:16:30,609 INFO storage.BlockManagerMasterEndpoint: Registering block manager mike.dm.isds.tugraz.at:45245 with 59.8 GiB RAM, BlockManagerId(1, mike.dm.isds.tugraz.at, 45245, None)
2022-08-04 10:16:30,694 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.17:50908) with ID 2,  ResourceProfileId 0
2022-08-04 10:16:30,810 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.19:41438) with ID 3,  ResourceProfileId 0
2022-08-04 10:16:30,856 INFO storage.BlockManagerMasterEndpoint: Registering block manager papa.dm.isds.tugraz.at:45069 with 59.8 GiB RAM, BlockManagerId(2, papa.dm.isds.tugraz.at, 45069, None)
2022-08-04 10:16:30,877 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2022-08-04 10:16:30,980 INFO storage.BlockManagerMasterEndpoint: Registering block manager romeo.dm.isds.tugraz.at:42023 with 59.8 GiB RAM, BlockManagerId(3, romeo.dm.isds.tugraz.at, 42023, None)
2022-08-04 10:16:31,088 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2022-08-04 10:16:31,090 INFO internal.SharedState: Warehouse path is 'file:/home/oovcharenko/benchmark/BS_OlgaOvcharenko/spark-warehouse'.
2022-08-04 10:16:31,106 INFO ui.ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 10:16:31,109 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7048ecee{/SQL,null,AVAILABLE,@Spark}
2022-08-04 10:16:31,109 INFO ui.ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 10:16:31,110 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@382a2870{/SQL/json,null,AVAILABLE,@Spark}
2022-08-04 10:16:31,111 INFO ui.ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 10:16:31,112 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5b6f57f1{/SQL/execution,null,AVAILABLE,@Spark}
2022-08-04 10:16:31,112 INFO ui.ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 10:16:31,113 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@73a3bbfd{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-08-04 10:16:31,114 INFO ui.ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 10:16:31,116 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@76ec2c66{/static/sql,null,AVAILABLE,@Spark}
Created integer part 15.155049324035645
Created data 15.354722738265991
Num of rows 409600000

F_NAME
Set values
Random sample 0.30225419998168945
Create errors lists sample 1.2680087089538574

L_NAME
Set values
Random sample 0.8331918716430664
Create errors lists sample 1.8732030391693115

CITY
Set values
Random sample 0.22646427154541016
Create errors lists sample 1.259037733078003

STATE
Set values
Random sample 0.2216634750366211
Create errors lists sample 1.1021242141723633
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/error_sequence_generator.py", line 357, in _run_col_distributed
    new_outliers_dict = AddOutliers().run(col_name=col, num_outliers=num_outliers,
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/errors.py", line 347, in run
    new_outlier_value = AddOutliers.get_outlier(outlier_type=outlier_type, err_dist=err_dist,
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/errors.py", line 422, in get_outlier
    new_outlier_value = upper_limit + abs(value)
TypeError: bad operand type for abs(): 'str'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/test_scale_up_distributed.py", line 23, in <module>
    generated_data = scale_modify.run_distributed(
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/scale_modify.py", line 179, in run_distributed
    data_gen.clean_data_scaled, new_error_dist = generate_errors_sp(spark=spark, generator=data_gen, scaled_schema=schema,
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/error_sequence_generator.py", line 66, in generate_errors_sp
    results = t.get()
  File "/usr/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
TypeError: bad operand type for abs(): 'str'

real	5m55.886s
user	2m33.994s
sys	7m43.394s
