WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.
Error dist count [274, 698, 0, 0, 0, 201, 600, 401, 200, 200, 3, 188, 200, 0, 200]
Original error count [274 698   0   0   0 201 600 401 200 200   3 188 200   0 200]
2022-08-04 05:04:49,689 INFO spark.SparkContext: Running Spark version 3.2.0
2022-08-04 05:04:49,783 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-08-04 05:04:49,924 INFO resource.ResourceUtils: ==============================================================
2022-08-04 05:04:49,925 INFO resource.ResourceUtils: No custom resources configured for spark.driver.
2022-08-04 05:04:49,925 INFO resource.ResourceUtils: ==============================================================
2022-08-04 05:04:49,926 INFO spark.SparkContext: Submitted application: DataGenerator_dirty_tax_64.0
2022-08-04 05:04:49,953 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 102400, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-08-04 05:04:49,978 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks per executor
2022-08-04 05:04:49,981 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0
2022-08-04 05:04:50,066 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-04 05:04:50,066 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-04 05:04:50,067 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-04 05:04:50,067 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-04 05:04:50,068 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-04 05:04:50,413 INFO util.Utils: Successfully started service 'sparkDriver' on port 40869.
2022-08-04 05:04:50,449 INFO spark.SparkEnv: Registering MapOutputTracker
2022-08-04 05:04:50,489 INFO spark.SparkEnv: Registering BlockManagerMaster
2022-08-04 05:04:50,510 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-08-04 05:04:50,511 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-08-04 05:04:50,556 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2022-08-04 05:04:50,584 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-d4cfbfe9-c8f6-49e9-9c5c-1627151ab036
2022-08-04 05:04:50,622 INFO memory.MemoryStore: MemoryStore started with capacity 434.4 MiB
2022-08-04 05:04:50,669 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2022-08-04 05:04:50,807 INFO util.log: Logging initialized @11481ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-08-04 05:04:50,883 INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-Ubuntu-0ubuntu1.20.04
2022-08-04 05:04:50,905 INFO server.Server: Started @11580ms
2022-08-04 05:04:50,949 INFO server.AbstractConnector: Started ServerConnector@28991dfd{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-08-04 05:04:50,949 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2022-08-04 05:04:50,977 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69966629{/jobs,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,980 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3b0389d5{/jobs/json,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,981 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5b40603d{/jobs/job,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,985 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@61630dc2{/jobs/job/json,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,986 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3effbed2{/stages,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,987 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b20714e{/stages/json,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,988 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5af72eea{/stages/stage,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,991 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@cbe28c2{/stages/stage/json,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,992 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70273047{/stages/pool,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,993 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@534bb4f0{/stages/pool/json,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,994 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5757f2d7{/storage,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,995 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4a8880a{/storage/json,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,996 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@289ce6ff{/storage/rdd,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,997 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@30aa7250{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,998 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@14bb017e{/environment,null,AVAILABLE,@Spark}
2022-08-04 05:04:50,999 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@15e4fdc2{/environment/json,null,AVAILABLE,@Spark}
2022-08-04 05:04:51,000 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f1e97f6{/executors,null,AVAILABLE,@Spark}
2022-08-04 05:04:51,002 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@42db9290{/executors/json,null,AVAILABLE,@Spark}
2022-08-04 05:04:51,003 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6c360a84{/executors/threadDump,null,AVAILABLE,@Spark}
2022-08-04 05:04:51,005 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1932873c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-08-04 05:04:51,015 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@46167677{/static,null,AVAILABLE,@Spark}
2022-08-04 05:04:51,016 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a6ec121{/,null,AVAILABLE,@Spark}
2022-08-04 05:04:51,018 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@c22ee1c{/api,null,AVAILABLE,@Spark}
2022-08-04 05:04:51,019 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@55e9661b{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-08-04 05:04:51,020 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6b90ea71{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-08-04 05:04:51,022 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://tango.dm.isds.tugraz.at:4040
2022-08-04 05:04:51,381 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at charlie.dm.isds.tugraz.at/129.27.206.4:8032
2022-08-04 05:04:51,611 INFO yarn.Client: Requesting a new application from cluster with 9 NodeManagers
2022-08-04 05:04:52,146 INFO conf.Configuration: resource-types.xml not found
2022-08-04 05:04:52,146 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2022-08-04 05:04:52,160 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (122880 MB per container)
2022-08-04 05:04:52,161 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
2022-08-04 05:04:52,161 INFO yarn.Client: Setting up container launch context for our AM
2022-08-04 05:04:52,163 INFO yarn.Client: Setting up the launch environment for our AM container
2022-08-04 05:04:52,169 INFO yarn.Client: Preparing resources for our AM container
2022-08-04 05:04:52,792 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2022-08-04 05:04:55,248 INFO yarn.Client: Uploading resource file:/tmp/spark-5584c084-cf77-48e5-9ce8-0a820b072304/__spark_libs__11837401051154008866.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0197/__spark_libs__11837401051154008866.zip
2022-08-04 05:04:57,939 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/pyspark.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0197/pyspark.zip
2022-08-04 05:04:59,021 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/py4j-0.10.9.2-src.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0197/py4j-0.10.9.2-src.zip
2022-08-04 05:05:00,277 INFO yarn.Client: Uploading resource file:/tmp/spark-5584c084-cf77-48e5-9ce8-0a820b072304/__spark_conf__8742188382627562249.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0197/__spark_conf__.zip
2022-08-04 05:05:01,458 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-04 05:05:01,458 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-04 05:05:01,458 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-04 05:05:01,458 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-04 05:05:01,458 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-04 05:05:01,479 INFO yarn.Client: Submitting application application_1659444800769_0197 to ResourceManager
2022-08-04 05:05:01,521 INFO impl.YarnClientImpl: Submitted application application_1659444800769_0197
2022-08-04 05:05:02,525 INFO yarn.Client: Application report for application_1659444800769_0197 (state: ACCEPTED)
2022-08-04 05:05:02,528 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659582301495
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0197/
	 user: oovcharenko
2022-08-04 05:05:03,529 INFO yarn.Client: Application report for application_1659444800769_0197 (state: ACCEPTED)
2022-08-04 05:05:04,531 INFO yarn.Client: Application report for application_1659444800769_0197 (state: ACCEPTED)
2022-08-04 05:05:05,533 INFO yarn.Client: Application report for application_1659444800769_0197 (state: ACCEPTED)
2022-08-04 05:05:06,534 INFO yarn.Client: Application report for application_1659444800769_0197 (state: ACCEPTED)
2022-08-04 05:05:07,536 INFO yarn.Client: Application report for application_1659444800769_0197 (state: ACCEPTED)
2022-08-04 05:05:07,838 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> charlie.dm.isds.tugraz.at, PROXY_URI_BASES -> http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0197), /proxy/application_1659444800769_0197
2022-08-04 05:05:08,538 INFO yarn.Client: Application report for application_1659444800769_0197 (state: RUNNING)
2022-08-04 05:05:08,538 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 129.27.206.15
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659582301495
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0197/
	 user: oovcharenko
2022-08-04 05:05:08,539 INFO cluster.YarnClientSchedulerBackend: Application application_1659444800769_0197 has started running.
2022-08-04 05:05:08,551 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44029.
2022-08-04 05:05:08,551 INFO netty.NettyBlockTransferService: Server created on tango.dm.isds.tugraz.at:44029
2022-08-04 05:05:08,553 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-08-04 05:05:08,560 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 44029, None)
2022-08-04 05:05:08,566 INFO storage.BlockManagerMasterEndpoint: Registering block manager tango.dm.isds.tugraz.at:44029 with 434.4 MiB RAM, BlockManagerId(driver, tango.dm.isds.tugraz.at, 44029, None)
2022-08-04 05:05:08,570 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 44029, None)
2022-08-04 05:05:08,572 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, tango.dm.isds.tugraz.at, 44029, None)
2022-08-04 05:05:08,706 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
2022-08-04 05:05:08,791 INFO ui.ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 05:05:08,794 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7397f3f7{/metrics/json,null,AVAILABLE,@Spark}
2022-08-04 05:05:14,589 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.14:34996) with ID 1,  ResourceProfileId 0
2022-08-04 05:05:14,620 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.19:48436) with ID 2,  ResourceProfileId 0
2022-08-04 05:05:14,771 INFO storage.BlockManagerMasterEndpoint: Registering block manager mike.dm.isds.tugraz.at:40585 with 59.8 GiB RAM, BlockManagerId(1, mike.dm.isds.tugraz.at, 40585, None)
2022-08-04 05:05:14,785 INFO storage.BlockManagerMasterEndpoint: Registering block manager romeo.dm.isds.tugraz.at:34467 with 59.8 GiB RAM, BlockManagerId(2, romeo.dm.isds.tugraz.at, 34467, None)
2022-08-04 05:05:15,222 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.17:36386) with ID 3,  ResourceProfileId 0
2022-08-04 05:05:15,243 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2022-08-04 05:05:15,383 INFO storage.BlockManagerMasterEndpoint: Registering block manager papa.dm.isds.tugraz.at:41757 with 59.8 GiB RAM, BlockManagerId(3, papa.dm.isds.tugraz.at, 41757, None)
2022-08-04 05:05:15,450 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2022-08-04 05:05:15,453 INFO internal.SharedState: Warehouse path is 'file:/home/oovcharenko/benchmark/BS_OlgaOvcharenko/spark-warehouse'.
2022-08-04 05:05:15,469 INFO ui.ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 05:05:15,471 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b530970{/SQL,null,AVAILABLE,@Spark}
2022-08-04 05:05:15,472 INFO ui.ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 05:05:15,473 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ce332f2{/SQL/json,null,AVAILABLE,@Spark}
2022-08-04 05:05:15,473 INFO ui.ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 05:05:15,475 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@14b92c29{/SQL/execution,null,AVAILABLE,@Spark}
2022-08-04 05:05:15,475 INFO ui.ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 05:05:15,476 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ce7c22d{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-08-04 05:05:15,477 INFO ui.ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 05:05:15,479 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5eb7e885{/static/sql,null,AVAILABLE,@Spark}
Created integer part 15.217911005020142
Created data 15.421142816543579
Num of rows 12800000

F_NAME
Set values
Random sample 0.01375579833984375
Create errors lists sample 1.0027589797973633

L_NAME
Set values
Random sample 0.03444957733154297
Create errors lists sample 0.9379165172576904

CITY
Set values
Random sample 0.00971841812133789
Create errors lists sample 0.7199993133544922

STATE
Set values
Random sample 0.009730815887451172
Create errors lists sample 0.9447178840637207
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/error_sequence_generator.py", line 357, in _run_col_distributed
    new_outliers_dict = AddOutliers().run(col_name=col, num_outliers=num_outliers,
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/errors.py", line 347, in run
    new_outlier_value = AddOutliers.get_outlier(outlier_type=outlier_type, err_dist=err_dist,
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/errors.py", line 419, in get_outlier
    new_outlier_value = lower_limit - abs(value)
TypeError: bad operand type for abs(): 'str'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/test_scale_up_distributed.py", line 23, in <module>
    generated_data = scale_modify.run_distributed(
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/scale_modify.py", line 179, in run_distributed
    data_gen.clean_data_scaled, new_error_dist = generate_errors_sp(spark=spark, generator=data_gen, scaled_schema=schema,
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/error_sequence_generator.py", line 66, in generate_errors_sp
    results = t.get()
  File "/usr/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
TypeError: bad operand type for abs(): 'str'

real	1m5.123s
user	0m54.343s
sys	0m25.099s
