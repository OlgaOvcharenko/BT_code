WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.
Error dist count [0, 0, 0, 911, 1558, 1100, 1351]
Original error count [   0    0    0  911 1558 1100 1351]
2022-08-05 15:37:18,564 INFO spark.SparkContext: Running Spark version 3.2.0
2022-08-05 15:37:18,661 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-08-05 15:37:18,807 INFO resource.ResourceUtils: ==============================================================
2022-08-05 15:37:18,808 INFO resource.ResourceUtils: No custom resources configured for spark.driver.
2022-08-05 15:37:18,808 INFO resource.ResourceUtils: ==============================================================
2022-08-05 15:37:18,808 INFO spark.SparkContext: Submitted application: DataGenerator_dirty_flights_8192.0
2022-08-05 15:37:18,836 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 102400, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-08-05 15:37:18,863 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks per executor
2022-08-05 15:37:18,865 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0
2022-08-05 15:37:18,955 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-05 15:37:18,956 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-05 15:37:18,956 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-05 15:37:18,957 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-05 15:37:18,957 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-05 15:37:19,288 INFO util.Utils: Successfully started service 'sparkDriver' on port 45103.
2022-08-05 15:37:19,323 INFO spark.SparkEnv: Registering MapOutputTracker
2022-08-05 15:37:19,363 INFO spark.SparkEnv: Registering BlockManagerMaster
2022-08-05 15:37:19,386 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-08-05 15:37:19,387 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-08-05 15:37:19,431 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2022-08-05 15:37:19,461 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-678688f5-d272-413f-89a0-f32d877d02ff
2022-08-05 15:37:19,497 INFO memory.MemoryStore: MemoryStore started with capacity 434.4 MiB
2022-08-05 15:37:19,546 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2022-08-05 15:37:19,676 INFO util.log: Logging initialized @5590ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-08-05 15:37:19,756 INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-Ubuntu-0ubuntu1.20.04
2022-08-05 15:37:19,779 INFO server.Server: Started @5694ms
2022-08-05 15:37:19,827 INFO server.AbstractConnector: Started ServerConnector@10ff1c04{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-08-05 15:37:19,827 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2022-08-05 15:37:19,857 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d6bdcca{/jobs,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,861 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@457766f7{/jobs/json,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,862 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4518f972{/jobs/job,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,865 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78f9e160{/jobs/job/json,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,867 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78949573{/stages,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,868 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@511914{/stages/json,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,869 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@36102105{/stages/stage,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,871 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d8af627{/stages/stage/json,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,873 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2239fa2a{/stages/pool,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,874 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@316d8886{/stages/pool/json,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,875 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@57352748{/storage,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,876 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6225db14{/storage/json,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,877 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@25c99294{/storage/rdd,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,878 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5cf27047{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,879 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@296cab29{/environment,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,880 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69be049f{/environment/json,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,881 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@23fd92fa{/executors,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,883 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@15928a8c{/executors/json,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,884 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1730a89d{/executors/threadDump,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,886 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@158e6b6c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,897 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@73503e22{/static,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,898 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1732915{/,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,900 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@37595062{/api,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,901 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@594d56ea{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,902 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3a00764f{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-08-05 15:37:19,904 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://tango.dm.isds.tugraz.at:4040
2022-08-05 15:37:20,277 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at charlie.dm.isds.tugraz.at/129.27.206.4:8032
2022-08-05 15:37:20,524 INFO yarn.Client: Requesting a new application from cluster with 9 NodeManagers
2022-08-05 15:37:21,035 INFO conf.Configuration: resource-types.xml not found
2022-08-05 15:37:21,035 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2022-08-05 15:37:21,048 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (122880 MB per container)
2022-08-05 15:37:21,049 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
2022-08-05 15:37:21,049 INFO yarn.Client: Setting up container launch context for our AM
2022-08-05 15:37:21,051 INFO yarn.Client: Setting up the launch environment for our AM container
2022-08-05 15:37:21,057 INFO yarn.Client: Preparing resources for our AM container
2022-08-05 15:37:21,343 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2022-08-05 15:37:23,481 INFO yarn.Client: Uploading resource file:/tmp/spark-abcfa276-b270-483c-bf6a-bf4bec656698/__spark_libs__7350479112551643677.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0241/__spark_libs__7350479112551643677.zip
2022-08-05 15:37:25,296 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/pyspark.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0241/pyspark.zip
2022-08-05 15:37:25,780 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/py4j-0.10.9.2-src.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0241/py4j-0.10.9.2-src.zip
2022-08-05 15:37:26,449 INFO yarn.Client: Uploading resource file:/tmp/spark-abcfa276-b270-483c-bf6a-bf4bec656698/__spark_conf__4516512403371254031.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0241/__spark_conf__.zip
2022-08-05 15:37:27,042 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-05 15:37:27,042 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-05 15:37:27,042 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-05 15:37:27,042 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-05 15:37:27,042 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-05 15:37:27,065 INFO yarn.Client: Submitting application application_1659444800769_0241 to ResourceManager
2022-08-05 15:37:27,345 INFO impl.YarnClientImpl: Submitted application application_1659444800769_0241
2022-08-05 15:37:28,349 INFO yarn.Client: Application report for application_1659444800769_0241 (state: ACCEPTED)
2022-08-05 15:37:28,353 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659706647099
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0241/
	 user: oovcharenko
2022-08-05 15:37:29,355 INFO yarn.Client: Application report for application_1659444800769_0241 (state: ACCEPTED)
2022-08-05 15:37:30,358 INFO yarn.Client: Application report for application_1659444800769_0241 (state: ACCEPTED)
2022-08-05 15:37:31,360 INFO yarn.Client: Application report for application_1659444800769_0241 (state: ACCEPTED)
2022-08-05 15:37:32,363 INFO yarn.Client: Application report for application_1659444800769_0241 (state: ACCEPTED)
2022-08-05 15:37:33,292 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> charlie.dm.isds.tugraz.at, PROXY_URI_BASES -> http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0241), /proxy/application_1659444800769_0241
2022-08-05 15:37:33,365 INFO yarn.Client: Application report for application_1659444800769_0241 (state: RUNNING)
2022-08-05 15:37:33,365 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 129.27.206.17
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659706647099
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0241/
	 user: oovcharenko
2022-08-05 15:37:33,367 INFO cluster.YarnClientSchedulerBackend: Application application_1659444800769_0241 has started running.
2022-08-05 15:37:33,378 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44407.
2022-08-05 15:37:33,378 INFO netty.NettyBlockTransferService: Server created on tango.dm.isds.tugraz.at:44407
2022-08-05 15:37:33,380 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-08-05 15:37:33,388 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 44407, None)
2022-08-05 15:37:33,394 INFO storage.BlockManagerMasterEndpoint: Registering block manager tango.dm.isds.tugraz.at:44407 with 434.4 MiB RAM, BlockManagerId(driver, tango.dm.isds.tugraz.at, 44407, None)
2022-08-05 15:37:33,399 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 44407, None)
2022-08-05 15:37:33,400 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, tango.dm.isds.tugraz.at, 44407, None)
2022-08-05 15:37:33,634 INFO ui.ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-05 15:37:33,637 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@23ec9209{/metrics/json,null,AVAILABLE,@Spark}
2022-08-05 15:37:34,117 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
2022-08-05 15:37:40,828 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.5:59774) with ID 1,  ResourceProfileId 0
2022-08-05 15:37:40,905 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.14:35574) with ID 2,  ResourceProfileId 0
2022-08-05 15:37:40,994 INFO storage.BlockManagerMasterEndpoint: Registering block manager delta.dm.isds.tugraz.at:41233 with 59.8 GiB RAM, BlockManagerId(1, delta.dm.isds.tugraz.at, 41233, None)
2022-08-05 15:37:41,071 INFO storage.BlockManagerMasterEndpoint: Registering block manager mike.dm.isds.tugraz.at:42583 with 59.8 GiB RAM, BlockManagerId(2, mike.dm.isds.tugraz.at, 42583, None)
2022-08-05 15:37:41,587 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.19:57330) with ID 3,  ResourceProfileId 0
2022-08-05 15:37:41,591 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2022-08-05 15:37:41,753 INFO storage.BlockManagerMasterEndpoint: Registering block manager romeo.dm.isds.tugraz.at:34187 with 59.8 GiB RAM, BlockManagerId(3, romeo.dm.isds.tugraz.at, 34187, None)
2022-08-05 15:37:41,799 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2022-08-05 15:37:41,802 INFO internal.SharedState: Warehouse path is 'file:/home/oovcharenko/benchmark/BS_OlgaOvcharenko/spark-warehouse'.
2022-08-05 15:37:41,818 INFO ui.ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-05 15:37:41,820 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3a12d365{/SQL,null,AVAILABLE,@Spark}
2022-08-05 15:37:41,820 INFO ui.ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-05 15:37:41,822 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@fc30311{/SQL/json,null,AVAILABLE,@Spark}
2022-08-05 15:37:41,822 INFO ui.ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-05 15:37:41,823 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@21c95da0{/SQL/execution,null,AVAILABLE,@Spark}
2022-08-05 15:37:41,823 INFO ui.ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-05 15:37:41,824 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@77492599{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-08-05 15:37:41,825 INFO ui.ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-05 15:37:41,827 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@36a78210{/static/sql,null,AVAILABLE,@Spark}
Created integer part 10.00766634941101
Created data 10.1821448802948
Num of rows 19464192

SCHED_DEP_TIME
Set values
Random sample 6.788548707962036
Create errors lists sample 14.014769315719604

ACT_DEP_TIME
Set values
Random sample 9.385979175567627
Create errors lists sample 19.56633710861206

SCHED_ARR_TIME
Set values
Random sample 8.416577339172363
Create errors lists sample 16.04033899307251

ACT_ARR_TIME
Set values
Random sample 8.887502431869507
Create errors lists sample 16.768065690994263
Create error DATAFRAME  0.34155774116516113
Create spark obj 0.34717583656311035
Set values after join, TOTAL 0.4123530387878418
Create error DATAFRAME  0.33553457260131836
Create spark obj 0.33980679512023926
Set values after join, TOTAL 0.37418508529663086
Create error DATAFRAME  0.45841145515441895
Create spark obj 0.4631466865539551
Set values after join, TOTAL 0.5006301403045654
Create error DATAFRAME  0.27685093879699707
Create spark obj 0.28133654594421387
Set values after join, TOTAL 0.3187217712402344
Replacements sched_dep_time
REPLACEMENT start
REPLACEMENT Num repl 	147456


REPLACEMENT Create replacement DATAFRAME  1804.4645669460297
REPLACEMENT Create spark obj 1804.4744210243225
REPLACEMENT all 1804.5063300132751
Replacements act_dep_time
REPLACEMENT start
REPLACEMENT Num repl 	1703936


REPLACEMENT Create replacement DATAFRAME  2242.465841770172
REPLACEMENT Create spark obj 2242.469255208969
REPLACEMENT all 2242.493418455124
Replacements sched_arr_time
REPLACEMENT start
REPLACEMENT Num repl 	163840


REPLACEMENT Create replacement DATAFRAME  2581.9412956237793
REPLACEMENT Create spark obj 2581.9453115463257
REPLACEMENT all 2581.9687328338623
Replacements act_arr_time
REPLACEMENT start
REPLACEMENT Num repl 	557056


REPLACEMENT Create replacement DATAFRAME  3040.9549231529236
REPLACEMENT Create spark obj 3040.958971261978
REPLACEMENT all 3040.9851429462433
Swaps numerical done
Swaps str
Generated dataset
Save dataset: 15843.844866991043

Error distribution computation: 0.718416690826416

Scale dataset: 34.32051396369934

Errors to scaled dataset: 9699.255615234375

Generated error distribution: 3722.4144287109375

--------------------------------------------------------
tuple_id
Mean original dirty: 	 1188.5
Mean generated dirty: 	 8.756913813868433

Var original dirty: 	 470646.0
Var generated dirty: 	 12224.195673909015

Q25 original dirty: 	 594.75
Q25 generated dirty: 	 1.0

INFO: Q25 differs from original dirty data

Q50 original dirty: 	 1188.5
Q50 generated dirty: 	 1.0

INFO: Q50 differs from original dirty data

Q75 original dirty: 	 1782.25
Q75 generated dirty: 	 1.0

INFO: Q75 differs from original dirty data

Min original dirty: 	 1
Min generated dirty: 	 1.0

Max original dirty: 	 2376
Max generated dirty: 	 2376.0

--------------------------------------------------------
--------------------------------------------------------
tuple_id
Distinct original dirty: 	 2376
Distinct original clean: 	 2376
Distinct estimated dirty (whole dataset): 	 19464192, distinct with ratio 	 19464192
Distinct estimated dirty (replicate + errors): 	 2376.0
Distinct generated dirty: 	 2093

--------------------------------------------------------
src
Distinct original dirty: 	 38
Distinct original clean: 	 38
Distinct estimated dirty (whole dataset): 	 169, distinct with ratio 	 169
Distinct estimated dirty (replicate + errors): 	 38.0
Distinct generated dirty: 	 29

--------------------------------------------------------
flight
Distinct original dirty: 	 100
Distinct original clean: 	 100
Distinct estimated dirty (whole dataset): 	 100, distinct with ratio 	 100
Distinct estimated dirty (replicate + errors): 	 100.0
Distinct generated dirty: 	 97

--------------------------------------------------------
sched_dep_time
Distinct original dirty: 	 138
Distinct original clean: 	 79
Distinct estimated dirty (whole dataset): 	 16821, distinct with ratio 	 16821
Distinct estimated dirty (replicate + errors): 	 19519.0
Distinct generated dirty: 	 14508

Replacements original dirty: 	 18
Replacements generated dirty: 	 126646

Traceback (most recent call last):
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/test_scale_up_distributed.py", line 23, in <module>
    generated_data = scale_modify.run_distributed(
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/scale_modify.py", line 206, in run_distributed
    compare_error_dist.compare_error_distributions_statistics_sp(
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/compare_error_dist.py", line 15, in compare_error_distributions_statistics_sp
    compare_distincts_sp(cols=cols, original=original, generated=generated)
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/compare_error_dist.py", line 270, in compare_distincts_sp
    assert round(original.distinct_replacements_count[c] * original.scaling_factor) * 0.9 <= \
AssertionError: In sched_dep_time changed replacements distribution, original - 147456, gen - 126646

real	488m26.535s
user	6m35.609s
sys	0m41.944s
