WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.
Error dist count [0, 0, 0, 911, 1558, 1100, 1351]
Original error count [   0    0    0  911 1558 1100 1351]
2022-08-08 02:45:14,142 INFO spark.SparkContext: Running Spark version 3.2.0
2022-08-08 02:45:14,243 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-08-08 02:45:14,387 INFO resource.ResourceUtils: ==============================================================
2022-08-08 02:45:14,388 INFO resource.ResourceUtils: No custom resources configured for spark.driver.
2022-08-08 02:45:14,388 INFO resource.ResourceUtils: ==============================================================
2022-08-08 02:45:14,388 INFO spark.SparkContext: Submitted application: DataGenerator_dirty_flights_8192.0
2022-08-08 02:45:14,417 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 102400, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-08-08 02:45:14,442 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks per executor
2022-08-08 02:45:14,444 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0
2022-08-08 02:45:14,510 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-08 02:45:14,510 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-08 02:45:14,511 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-08 02:45:14,511 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-08 02:45:14,512 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-08 02:45:14,860 INFO util.Utils: Successfully started service 'sparkDriver' on port 43539.
2022-08-08 02:45:14,897 INFO spark.SparkEnv: Registering MapOutputTracker
2022-08-08 02:45:14,939 INFO spark.SparkEnv: Registering BlockManagerMaster
2022-08-08 02:45:14,962 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-08-08 02:45:14,962 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-08-08 02:45:15,012 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2022-08-08 02:45:15,043 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-03d4dca4-4666-43d8-9127-d8ec5425ac45
2022-08-08 02:45:15,080 INFO memory.MemoryStore: MemoryStore started with capacity 53.8 GiB
2022-08-08 02:45:15,172 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2022-08-08 02:45:15,315 INFO util.log: Logging initialized @5899ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-08-08 02:45:15,408 INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-Ubuntu-0ubuntu1.20.04
2022-08-08 02:45:15,432 INFO server.Server: Started @6017ms
2022-08-08 02:45:15,480 INFO server.AbstractConnector: Started ServerConnector@6b8fab2{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-08-08 02:45:15,480 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2022-08-08 02:45:15,509 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4f1fecac{/jobs,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,513 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3e46b6fc{/jobs/json,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,514 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@67a0d571{/jobs/job,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,518 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4bd7ee3{/jobs/job/json,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,519 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@53b04ee{/stages,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,520 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1aee307{/stages/json,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,521 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4435d06c{/stages/stage,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,524 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@21b96b9f{/stages/stage/json,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,525 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2be79b5e{/stages/pool,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,526 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ef76eec{/stages/pool/json,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,527 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40e53cd1{/storage,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,529 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@518f313b{/storage/json,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,530 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1406c457{/storage/rdd,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,531 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2d997e8e{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,532 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1189a97c{/environment,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,533 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4e03a477{/environment/json,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,534 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e6757bc{/executors,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,535 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@63650b1d{/executors/json,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,536 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4b080c36{/executors/threadDump,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,538 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@162ce8e{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,550 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@160ca472{/static,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,551 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2c397ea3{/,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,553 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1a0b3c6e{/api,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,554 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@267ec6b8{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,555 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3acf855f{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-08-08 02:45:15,557 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://tango.dm.isds.tugraz.at:4040
2022-08-08 02:45:15,914 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at charlie.dm.isds.tugraz.at/129.27.206.4:8032
2022-08-08 02:45:16,164 INFO yarn.Client: Requesting a new application from cluster with 9 NodeManagers
2022-08-08 02:45:16,666 INFO conf.Configuration: resource-types.xml not found
2022-08-08 02:45:16,667 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2022-08-08 02:45:16,679 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (122880 MB per container)
2022-08-08 02:45:16,679 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
2022-08-08 02:45:16,680 INFO yarn.Client: Setting up container launch context for our AM
2022-08-08 02:45:16,681 INFO yarn.Client: Setting up the launch environment for our AM container
2022-08-08 02:45:16,686 INFO yarn.Client: Preparing resources for our AM container
2022-08-08 02:45:17,327 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2022-08-08 02:45:19,670 INFO yarn.Client: Uploading resource file:/tmp/spark-169337b9-ff4d-4089-b6e2-4fe7109820ff/__spark_libs__9545083591952307972.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0316/__spark_libs__9545083591952307972.zip
2022-08-08 02:45:22,536 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/pyspark.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0316/pyspark.zip
2022-08-08 02:45:23,672 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/py4j-0.10.9.2-src.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0316/py4j-0.10.9.2-src.zip
2022-08-08 02:45:24,989 INFO yarn.Client: Uploading resource file:/tmp/spark-169337b9-ff4d-4089-b6e2-4fe7109820ff/__spark_conf__18430881863458724822.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0316/__spark_conf__.zip
2022-08-08 02:45:26,135 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-08 02:45:26,135 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-08 02:45:26,135 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-08 02:45:26,135 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-08 02:45:26,135 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-08 02:45:26,157 INFO yarn.Client: Submitting application application_1659444800769_0316 to ResourceManager
2022-08-08 02:45:26,197 INFO impl.YarnClientImpl: Submitted application application_1659444800769_0316
2022-08-08 02:45:27,201 INFO yarn.Client: Application report for application_1659444800769_0316 (state: ACCEPTED)
2022-08-08 02:45:27,204 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659919526172
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0316/
	 user: oovcharenko
2022-08-08 02:45:28,206 INFO yarn.Client: Application report for application_1659444800769_0316 (state: ACCEPTED)
2022-08-08 02:45:29,207 INFO yarn.Client: Application report for application_1659444800769_0316 (state: ACCEPTED)
2022-08-08 02:45:30,209 INFO yarn.Client: Application report for application_1659444800769_0316 (state: ACCEPTED)
2022-08-08 02:45:31,210 INFO yarn.Client: Application report for application_1659444800769_0316 (state: ACCEPTED)
2022-08-08 02:45:32,212 INFO yarn.Client: Application report for application_1659444800769_0316 (state: ACCEPTED)
2022-08-08 02:45:32,840 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> charlie.dm.isds.tugraz.at, PROXY_URI_BASES -> http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0316), /proxy/application_1659444800769_0316
2022-08-08 02:45:33,213 INFO yarn.Client: Application report for application_1659444800769_0316 (state: RUNNING)
2022-08-08 02:45:33,214 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 129.27.206.5
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659919526172
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0316/
	 user: oovcharenko
2022-08-08 02:45:33,216 INFO cluster.YarnClientSchedulerBackend: Application application_1659444800769_0316 has started running.
2022-08-08 02:45:33,227 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35859.
2022-08-08 02:45:33,228 INFO netty.NettyBlockTransferService: Server created on tango.dm.isds.tugraz.at:35859
2022-08-08 02:45:33,230 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-08-08 02:45:33,238 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 35859, None)
2022-08-08 02:45:33,244 INFO storage.BlockManagerMasterEndpoint: Registering block manager tango.dm.isds.tugraz.at:35859 with 53.8 GiB RAM, BlockManagerId(driver, tango.dm.isds.tugraz.at, 35859, None)
2022-08-08 02:45:33,248 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 35859, None)
2022-08-08 02:45:33,249 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, tango.dm.isds.tugraz.at, 35859, None)
2022-08-08 02:45:33,446 INFO ui.ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-08 02:45:33,449 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@68497fe5{/metrics/json,null,AVAILABLE,@Spark}
2022-08-08 02:45:33,737 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
2022-08-08 02:45:39,886 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.16:51560) with ID 1,  ResourceProfileId 0
2022-08-08 02:45:39,901 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.24:47926) with ID 3,  ResourceProfileId 0
2022-08-08 02:45:40,052 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.13:53704) with ID 2,  ResourceProfileId 0
2022-08-08 02:45:40,060 INFO storage.BlockManagerMasterEndpoint: Registering block manager oscar.dm.isds.tugraz.at:34953 with 59.8 GiB RAM, BlockManagerId(1, oscar.dm.isds.tugraz.at, 34953, None)
2022-08-08 02:45:40,069 INFO storage.BlockManagerMasterEndpoint: Registering block manager whiskey.dm.isds.tugraz.at:35733 with 59.8 GiB RAM, BlockManagerId(3, whiskey.dm.isds.tugraz.at, 35733, None)
2022-08-08 02:45:40,104 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2022-08-08 02:45:40,218 INFO storage.BlockManagerMasterEndpoint: Registering block manager lima.dm.isds.tugraz.at:38473 with 59.8 GiB RAM, BlockManagerId(2, lima.dm.isds.tugraz.at, 38473, None)
2022-08-08 02:45:40,313 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2022-08-08 02:45:40,316 INFO internal.SharedState: Warehouse path is 'file:/home/oovcharenko/benchmark/BS_OlgaOvcharenko/spark-warehouse'.
2022-08-08 02:45:40,333 INFO ui.ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-08 02:45:40,335 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@cc0f521{/SQL,null,AVAILABLE,@Spark}
2022-08-08 02:45:40,335 INFO ui.ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-08 02:45:40,336 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@425605f5{/SQL/json,null,AVAILABLE,@Spark}
2022-08-08 02:45:40,337 INFO ui.ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-08 02:45:40,338 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@475e1a1f{/SQL/execution,null,AVAILABLE,@Spark}
2022-08-08 02:45:40,338 INFO ui.ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-08 02:45:40,339 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@58b34257{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-08-08 02:45:40,340 INFO ui.ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-08 02:45:40,342 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@457d8844{/static/sql,null,AVAILABLE,@Spark}
Created integer part 8.01668930053711
Created data 8.192624568939209
Num of rows 19464192
Replacements sched_dep_time
REPLACEMENT start
REPLACEMENT Num repl 	147456


REPLACEMENT Create replacement DATAFRAME  67.53542256355286
REPLACEMENT Create spark obj 67.54050278663635
REPLACEMENT all 67.59961557388306
Replacements act_dep_time
REPLACEMENT start
REPLACEMENT Num repl 	1703936


REPLACEMENT Create replacement DATAFRAME  42.95449781417847
REPLACEMENT Create spark obj 42.9586136341095
REPLACEMENT all 42.986409187316895
Replacements sched_arr_time
REPLACEMENT start
REPLACEMENT Num repl 	163840


REPLACEMENT Create replacement DATAFRAME  34.26754546165466
REPLACEMENT Create spark obj 34.27162051200867
REPLACEMENT all 34.2984037399292
Replacements act_arr_time
REPLACEMENT start
REPLACEMENT Num repl 	557056


REPLACEMENT Create replacement DATAFRAME  41.12687945365906
REPLACEMENT Create spark obj 41.131000995635986
REPLACEMENT all 41.1569287776947

SCHED_DEP_TIME
Set values
Random sample 9.55853819847107
Create errors lists sample 16.301621675491333

ACT_DEP_TIME
Set values
Random sample 9.314383745193481
Create errors lists sample 17.6414852142334

SCHED_ARR_TIME
Set values
Random sample 9.522028684616089
Create errors lists sample 18.968624114990234

ACT_ARR_TIME
Set values
Random sample 9.433152914047241
Create errors lists sample 18.5859797000885
Create error DATAFRAME  0.15190458297729492
Create spark obj 0.1560506820678711
Set values after join, TOTAL 0.18232345581054688
Create error DATAFRAME  0.16929197311401367
Create spark obj 0.17321562767028809
Set values after join, TOTAL 0.19901823997497559
Create error DATAFRAME  0.142075777053833
Create spark obj 0.1465308666229248
Set values after join, TOTAL 0.17320895195007324
Create error DATAFRAME  0.13882994651794434
Create spark obj 0.14277219772338867
Set values after join, TOTAL 0.16984772682189941
Swaps numerical done
Swaps str
Generated dataset
