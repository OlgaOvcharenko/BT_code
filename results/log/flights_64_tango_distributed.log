WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.
Error dist count [0, 0, 0, 911, 1558, 1100, 1351]
Original error count [   0    0    0  911 1558 1100 1351]
2022-08-04 05:02:49,974 INFO spark.SparkContext: Running Spark version 3.2.0
2022-08-04 05:02:50,073 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-08-04 05:02:50,224 INFO resource.ResourceUtils: ==============================================================
2022-08-04 05:02:50,225 INFO resource.ResourceUtils: No custom resources configured for spark.driver.
2022-08-04 05:02:50,225 INFO resource.ResourceUtils: ==============================================================
2022-08-04 05:02:50,225 INFO spark.SparkContext: Submitted application: DataGenerator_dirty_flights_64.0
2022-08-04 05:02:50,254 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 102400, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-08-04 05:02:50,279 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks per executor
2022-08-04 05:02:50,281 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0
2022-08-04 05:02:50,367 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-04 05:02:50,368 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-04 05:02:50,368 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-04 05:02:50,368 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-04 05:02:50,369 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-04 05:02:50,698 INFO util.Utils: Successfully started service 'sparkDriver' on port 32799.
2022-08-04 05:02:50,734 INFO spark.SparkEnv: Registering MapOutputTracker
2022-08-04 05:02:50,775 INFO spark.SparkEnv: Registering BlockManagerMaster
2022-08-04 05:02:50,797 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-08-04 05:02:50,798 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-08-04 05:02:50,845 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2022-08-04 05:02:50,873 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-7458064e-e0f1-41d6-b20f-eab5deaed46a
2022-08-04 05:02:50,912 INFO memory.MemoryStore: MemoryStore started with capacity 434.4 MiB
2022-08-04 05:02:50,960 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2022-08-04 05:02:51,099 INFO util.log: Logging initialized @5538ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-08-04 05:02:51,177 INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-Ubuntu-0ubuntu1.20.04
2022-08-04 05:02:51,199 INFO server.Server: Started @5640ms
2022-08-04 05:02:51,246 INFO server.AbstractConnector: Started ServerConnector@6be8e063{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-08-04 05:02:51,246 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2022-08-04 05:02:51,276 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@41c4a410{/jobs,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,279 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@51a8a7a0{/jobs/json,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,280 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@29ad540f{/jobs/job,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,283 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@684adb6d{/jobs/job/json,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,284 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f04a7fd{/stages,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,286 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26c39636{/stages/json,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,287 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a65142e{/stages/stage,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,289 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@431ff95{/stages/stage/json,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,290 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@636c152d{/stages/pool,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,292 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ea25178{/stages/pool/json,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,293 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@472ff672{/storage,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,294 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78252d11{/storage/json,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,295 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4ed334ce{/storage/rdd,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,296 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5f54f2fa{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,297 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40c94d83{/environment,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,298 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@76281224{/environment/json,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,299 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@30d729d2{/executors,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,300 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@174bb0ca{/executors/json,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,302 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@622d8362{/executors/threadDump,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,304 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@28110aa4{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,315 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20612fbc{/static,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,316 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@41738b5e{/,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,318 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c79dfc3{/api,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,319 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3dc59c56{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,320 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@271bfeb3{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-08-04 05:02:51,322 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://tango.dm.isds.tugraz.at:4040
2022-08-04 05:02:51,688 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at charlie.dm.isds.tugraz.at/129.27.206.4:8032
2022-08-04 05:02:51,915 INFO yarn.Client: Requesting a new application from cluster with 9 NodeManagers
2022-08-04 05:02:52,443 INFO conf.Configuration: resource-types.xml not found
2022-08-04 05:02:52,443 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2022-08-04 05:02:52,457 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (122880 MB per container)
2022-08-04 05:02:52,457 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
2022-08-04 05:02:52,458 INFO yarn.Client: Setting up container launch context for our AM
2022-08-04 05:02:52,460 INFO yarn.Client: Setting up the launch environment for our AM container
2022-08-04 05:02:52,466 INFO yarn.Client: Preparing resources for our AM container
2022-08-04 05:02:53,114 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2022-08-04 05:02:55,535 INFO yarn.Client: Uploading resource file:/tmp/spark-f21700a6-2c3a-401e-866b-6514177934b9/__spark_libs__16654466428037966927.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0196/__spark_libs__16654466428037966927.zip
2022-08-04 05:02:58,299 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/pyspark.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0196/pyspark.zip
2022-08-04 05:02:59,476 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/py4j-0.10.9.2-src.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0196/py4j-0.10.9.2-src.zip
2022-08-04 05:03:00,729 INFO yarn.Client: Uploading resource file:/tmp/spark-f21700a6-2c3a-401e-866b-6514177934b9/__spark_conf__15629274930457706056.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0196/__spark_conf__.zip
2022-08-04 05:03:01,781 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-04 05:03:01,781 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-04 05:03:01,781 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-04 05:03:01,781 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-04 05:03:01,781 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-04 05:03:01,804 INFO yarn.Client: Submitting application application_1659444800769_0196 to ResourceManager
2022-08-04 05:03:01,846 INFO impl.YarnClientImpl: Submitted application application_1659444800769_0196
2022-08-04 05:03:02,849 INFO yarn.Client: Application report for application_1659444800769_0196 (state: ACCEPTED)
2022-08-04 05:03:02,852 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659582181819
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0196/
	 user: oovcharenko
2022-08-04 05:03:03,854 INFO yarn.Client: Application report for application_1659444800769_0196 (state: ACCEPTED)
2022-08-04 05:03:04,856 INFO yarn.Client: Application report for application_1659444800769_0196 (state: ACCEPTED)
2022-08-04 05:03:05,858 INFO yarn.Client: Application report for application_1659444800769_0196 (state: ACCEPTED)
2022-08-04 05:03:06,859 INFO yarn.Client: Application report for application_1659444800769_0196 (state: ACCEPTED)
2022-08-04 05:03:07,861 INFO yarn.Client: Application report for application_1659444800769_0196 (state: RUNNING)
2022-08-04 05:03:07,861 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 129.27.206.19
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659582181819
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0196/
	 user: oovcharenko
2022-08-04 05:03:07,863 INFO cluster.YarnClientSchedulerBackend: Application application_1659444800769_0196 has started running.
2022-08-04 05:03:07,874 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40385.
2022-08-04 05:03:07,874 INFO netty.NettyBlockTransferService: Server created on tango.dm.isds.tugraz.at:40385
2022-08-04 05:03:07,876 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-08-04 05:03:07,884 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 40385, None)
2022-08-04 05:03:07,894 INFO storage.BlockManagerMasterEndpoint: Registering block manager tango.dm.isds.tugraz.at:40385 with 434.4 MiB RAM, BlockManagerId(driver, tango.dm.isds.tugraz.at, 40385, None)
2022-08-04 05:03:07,900 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 40385, None)
2022-08-04 05:03:07,901 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, tango.dm.isds.tugraz.at, 40385, None)
2022-08-04 05:03:08,015 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> charlie.dm.isds.tugraz.at, PROXY_URI_BASES -> http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0196), /proxy/application_1659444800769_0196
2022-08-04 05:03:08,142 INFO ui.ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 05:03:08,145 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@501bfa81{/metrics/json,null,AVAILABLE,@Spark}
2022-08-04 05:03:08,867 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
2022-08-04 05:03:12,421 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.19:46972) with ID 1,  ResourceProfileId 0
2022-08-04 05:03:12,584 INFO storage.BlockManagerMasterEndpoint: Registering block manager romeo.dm.isds.tugraz.at:33203 with 59.8 GiB RAM, BlockManagerId(1, romeo.dm.isds.tugraz.at, 33203, None)
2022-08-04 05:03:14,839 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.16:56922) with ID 2,  ResourceProfileId 0
2022-08-04 05:03:14,912 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.17:54736) with ID 3,  ResourceProfileId 0
2022-08-04 05:03:14,998 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2022-08-04 05:03:15,000 INFO storage.BlockManagerMasterEndpoint: Registering block manager oscar.dm.isds.tugraz.at:35175 with 59.8 GiB RAM, BlockManagerId(2, oscar.dm.isds.tugraz.at, 35175, None)
2022-08-04 05:03:15,071 INFO storage.BlockManagerMasterEndpoint: Registering block manager papa.dm.isds.tugraz.at:37281 with 59.8 GiB RAM, BlockManagerId(3, papa.dm.isds.tugraz.at, 37281, None)
2022-08-04 05:03:15,208 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2022-08-04 05:03:15,211 INFO internal.SharedState: Warehouse path is 'file:/home/oovcharenko/benchmark/BS_OlgaOvcharenko/spark-warehouse'.
2022-08-04 05:03:15,227 INFO ui.ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 05:03:15,229 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1602212e{/SQL,null,AVAILABLE,@Spark}
2022-08-04 05:03:15,230 INFO ui.ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 05:03:15,231 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65b42d23{/SQL/json,null,AVAILABLE,@Spark}
2022-08-04 05:03:15,231 INFO ui.ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 05:03:15,233 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2c8bc63f{/SQL/execution,null,AVAILABLE,@Spark}
2022-08-04 05:03:15,233 INFO ui.ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 05:03:15,234 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@395956ee{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-08-04 05:03:15,235 INFO ui.ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 05:03:15,236 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1b1a7119{/static/sql,null,AVAILABLE,@Spark}
Created integer part 7.786742448806763
Created data 7.960613965988159
Num of rows 152064

SCHED_DEP_TIME
Set values
Random sample 0.04304695129394531
Create errors lists sample 1.3986177444458008

ACT_DEP_TIME
Set values
Random sample 0.06511068344116211
Create errors lists sample 1.6678316593170166

SCHED_ARR_TIME
Set values
Random sample 0.05172109603881836
Create errors lists sample 1.6362438201904297

ACT_ARR_TIME
Set values
Random sample 0.06135201454162598
Create errors lists sample 1.641834020614624
Create error DATAFRAME  0.27820611000061035
Create spark obj 0.28374290466308594
Set values after join, TOTAL 0.34783124923706055
Create error DATAFRAME  0.2530248165130615
Create spark obj 0.2577946186065674
Set values after join, TOTAL 0.2920517921447754
Create error DATAFRAME  0.23430347442626953
Create spark obj 0.23928499221801758
Set values after join, TOTAL 0.27607274055480957
Create error DATAFRAME  2.3624775409698486
Create spark obj 2.3668482303619385
Set values after join, TOTAL 2.401057004928589
Replacements sched_dep_time
REPLACEMENT start
REPLACEMENT Num repl 	1152


REPLACEMENT Create replacement DATAFRAME  6.7394938468933105
REPLACEMENT Create spark obj 6.74360203742981
REPLACEMENT all 6.778217554092407
Replacements act_dep_time
REPLACEMENT start
REPLACEMENT Num repl 	13312


REPLACEMENT Create replacement DATAFRAME  9.35919713973999
REPLACEMENT Create spark obj 9.363358497619629
REPLACEMENT all 9.38827133178711
Replacements sched_arr_time
REPLACEMENT start
REPLACEMENT Num repl 	1280


REPLACEMENT Create replacement DATAFRAME  6.309704065322876
REPLACEMENT Create spark obj 6.313508033752441
REPLACEMENT all 6.336618900299072
Replacements act_arr_time
REPLACEMENT start
REPLACEMENT Num repl 	4352


REPLACEMENT Create replacement DATAFRAME  5.169522523880005
REPLACEMENT Create spark obj 5.1732566356658936
REPLACEMENT all 5.195826530456543
Swaps numerical done
Swaps str
Generated dataset
Save dataset: 25.129026889801025

Error distribution computation: 0.7047667503356934

Scale dataset: 34.09691524505615

Errors to scaled dataset: 33.04239010810852

Generated error distribution: 3.8235859870910645

--------------------------------------------------------
tuple_id
Mean original dirty: 	 1188.5
Mean generated dirty: 	 1188.5

Var original dirty: 	 470646.0
Var generated dirty: 	 470451.01043646486

Q25 original dirty: 	 594.75
Q25 generated dirty: 	 1.0

INFO: Q25 differs from original dirty data

Q50 original dirty: 	 1188.5
Q50 generated dirty: 	 607.0

INFO: Q50 differs from original dirty data

Q75 original dirty: 	 1782.25
Q75 generated dirty: 	 1.0

INFO: Q75 differs from original dirty data

Min original dirty: 	 1
Min generated dirty: 	 1.0

Max original dirty: 	 2376
Max generated dirty: 	 2376.0

--------------------------------------------------------
--------------------------------------------------------
tuple_id
Distinct original dirty: 	 2376
Distinct original clean: 	 2376
Distinct estimated dirty (whole dataset): 	 152064, distinct with ratio 	 152064
Distinct estimated dirty (replicate + errors): 	 2376.0
Distinct generated dirty: 	 2093

--------------------------------------------------------
src
Distinct original dirty: 	 38
Distinct original clean: 	 38
Distinct estimated dirty (whole dataset): 	 40, distinct with ratio 	 40
Distinct estimated dirty (replicate + errors): 	 38.0
Distinct generated dirty: 	 29

--------------------------------------------------------
flight
Distinct original dirty: 	 100
Distinct original clean: 	 100
Distinct estimated dirty (whole dataset): 	 100, distinct with ratio 	 100
Distinct estimated dirty (replicate + errors): 	 100.0
Distinct generated dirty: 	 97

--------------------------------------------------------
sched_dep_time
Distinct original dirty: 	 138
Distinct original clean: 	 79
Distinct estimated dirty (whole dataset): 	 370, distinct with ratio 	 370
Distinct estimated dirty (replicate + errors): 	 1275.0
Distinct generated dirty: 	 1504

Replacements original dirty: 	 18
Replacements generated dirty: 	 1152

Typos original dirty: 	 893
Typos generated dirty: 	 57152

Distinct estimated typo: 	 1196
Unique typos count - original dirty: 	 59
Unique typos count - generated dirty: 	 1188

--------------------------------------------------------
act_dep_time
Distinct original dirty: 	 291
Distinct original clean: 	 91
Distinct estimated dirty (whole dataset): 	 1038, distinct with ratio 	 1038
Distinct estimated dirty (replicate + errors): 	 1283.0
Distinct generated dirty: 	 1273

Replacements original dirty: 	 208
Replacements generated dirty: 	 12756

Typos original dirty: 	 1350
Typos generated dirty: 	 86400

Distinct estimated typo: 	 1192
Unique typos count - original dirty: 	 206
Unique typos count - generated dirty: 	 1188

--------------------------------------------------------
sched_arr_time
Distinct original dirty: 	 240
Distinct original clean: 	 94
Distinct estimated dirty (whole dataset): 	 774, distinct with ratio 	 774
Distinct estimated dirty (replicate + errors): 	 1737.0
Distinct generated dirty: 	 1380

Replacements original dirty: 	 20
Replacements generated dirty: 	 1280

Typos original dirty: 	 1080
Typos generated dirty: 	 69120

Distinct estimated typo: 	 1643
Unique typos count - original dirty: 	 146
Unique typos count - generated dirty: 	 1624

--------------------------------------------------------
act_arr_time
Distinct original dirty: 	 329
Distinct original clean: 	 96
Distinct estimated dirty (whole dataset): 	 1163, distinct with ratio 	 1163
Distinct estimated dirty (replicate + errors): 	 1586.0
Distinct generated dirty: 	 1443

Replacements original dirty: 	 68
Replacements generated dirty: 	 4352

Typos original dirty: 	 1283
Typos generated dirty: 	 82112

Distinct estimated typo: 	 1490
Unique typos count - original dirty: 	 240
Unique typos count - generated dirty: 	 1485

Validation 0.001071929931640625

Time elapsed 98.49050498008728

+++++++++++++++++++++++++++++++

real	1m42.871s
user	1m37.112s
sys	0m10.319s
