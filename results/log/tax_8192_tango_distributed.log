WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.
Error dist count [274, 698, 0, 0, 0, 201, 600, 401, 200, 200, 3, 188, 200, 0, 200]
Original error count [274 698   0   0   0 201 600 401 200 200   3 188 200   0 200]
2022-08-06 10:01:48,311 INFO spark.SparkContext: Running Spark version 3.2.0
2022-08-06 10:01:48,409 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-08-06 10:01:48,553 INFO resource.ResourceUtils: ==============================================================
2022-08-06 10:01:48,553 INFO resource.ResourceUtils: No custom resources configured for spark.driver.
2022-08-06 10:01:48,553 INFO resource.ResourceUtils: ==============================================================
2022-08-06 10:01:48,554 INFO spark.SparkContext: Submitted application: DataGenerator_dirty_tax_8192.0
2022-08-06 10:01:48,581 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 102400, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-08-06 10:01:48,605 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks per executor
2022-08-06 10:01:48,617 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0
2022-08-06 10:01:48,693 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-06 10:01:48,693 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-06 10:01:48,693 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-06 10:01:48,694 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-06 10:01:48,694 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-06 10:01:49,026 INFO util.Utils: Successfully started service 'sparkDriver' on port 40109.
2022-08-06 10:01:49,062 INFO spark.SparkEnv: Registering MapOutputTracker
2022-08-06 10:01:49,103 INFO spark.SparkEnv: Registering BlockManagerMaster
2022-08-06 10:01:49,125 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-08-06 10:01:49,125 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-08-06 10:01:49,170 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2022-08-06 10:01:49,200 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-dd72b091-6e3b-41b0-b137-e78d7b0786e8
2022-08-06 10:01:49,236 INFO memory.MemoryStore: MemoryStore started with capacity 434.4 MiB
2022-08-06 10:01:49,284 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2022-08-06 10:01:49,421 INFO util.log: Logging initialized @11528ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-08-06 10:01:49,499 INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-Ubuntu-0ubuntu1.20.04
2022-08-06 10:01:49,522 INFO server.Server: Started @11630ms
2022-08-06 10:01:49,567 INFO server.AbstractConnector: Started ServerConnector@4be97bf8{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-08-06 10:01:49,568 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2022-08-06 10:01:49,597 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20de983c{/jobs,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,600 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f1bef7f{/jobs/json,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,601 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6daa2036{/jobs/job,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,605 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@175b2a04{/jobs/job/json,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,606 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7ee51335{/stages,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,607 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@439f1378{/stages/json,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,608 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3a442f73{/stages/stage,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,610 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1938d881{/stages/stage/json,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,612 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26a2f12e{/stages/pool,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,613 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3927f1af{/stages/pool/json,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,614 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@613b9fb3{/storage,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,615 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@275a9883{/storage/json,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,616 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4321f4f0{/storage/rdd,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,617 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@24d2959c{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,618 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@47393ea1{/environment,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,619 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c685582{/environment/json,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,620 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@47a6b16a{/executors,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,621 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@71b29a5{/executors/json,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,622 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1eddd0c6{/executors/threadDump,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,625 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@545ae542{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,636 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@580124de{/static,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,637 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@734a85be{/,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,638 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20efb4f1{/api,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,639 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@38e32c8b{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,640 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56e8aa22{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-08-06 10:01:49,642 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://tango.dm.isds.tugraz.at:4040
2022-08-06 10:01:50,010 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at charlie.dm.isds.tugraz.at/129.27.206.4:8032
2022-08-06 10:01:50,240 INFO yarn.Client: Requesting a new application from cluster with 9 NodeManagers
2022-08-06 10:01:50,766 INFO conf.Configuration: resource-types.xml not found
2022-08-06 10:01:50,766 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2022-08-06 10:01:50,779 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (122880 MB per container)
2022-08-06 10:01:50,780 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
2022-08-06 10:01:50,780 INFO yarn.Client: Setting up container launch context for our AM
2022-08-06 10:01:50,782 INFO yarn.Client: Setting up the launch environment for our AM container
2022-08-06 10:01:50,787 INFO yarn.Client: Preparing resources for our AM container
2022-08-06 10:01:51,417 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2022-08-06 10:01:53,745 INFO yarn.Client: Uploading resource file:/tmp/spark-3b1d003d-8ace-4764-81d1-88b2a7955933/__spark_libs__9037236088597861364.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0279/__spark_libs__9037236088597861364.zip
2022-08-06 10:01:56,554 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/pyspark.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0279/pyspark.zip
2022-08-06 10:01:56,945 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/py4j-0.10.9.2-src.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0279/py4j-0.10.9.2-src.zip
2022-08-06 10:01:57,470 INFO yarn.Client: Uploading resource file:/tmp/spark-3b1d003d-8ace-4764-81d1-88b2a7955933/__spark_conf__14900428581747082310.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0279/__spark_conf__.zip
2022-08-06 10:01:58,608 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-06 10:01:58,608 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-06 10:01:58,608 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-06 10:01:58,608 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-06 10:01:58,608 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-06 10:01:58,629 INFO yarn.Client: Submitting application application_1659444800769_0279 to ResourceManager
2022-08-06 10:01:58,671 INFO impl.YarnClientImpl: Submitted application application_1659444800769_0279
2022-08-06 10:01:59,674 INFO yarn.Client: Application report for application_1659444800769_0279 (state: ACCEPTED)
2022-08-06 10:01:59,677 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659772918644
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0279/
	 user: oovcharenko
2022-08-06 10:02:00,679 INFO yarn.Client: Application report for application_1659444800769_0279 (state: ACCEPTED)
2022-08-06 10:02:01,681 INFO yarn.Client: Application report for application_1659444800769_0279 (state: ACCEPTED)
2022-08-06 10:02:02,683 INFO yarn.Client: Application report for application_1659444800769_0279 (state: ACCEPTED)
2022-08-06 10:02:03,684 INFO yarn.Client: Application report for application_1659444800769_0279 (state: ACCEPTED)
2022-08-06 10:02:04,686 INFO yarn.Client: Application report for application_1659444800769_0279 (state: RUNNING)
2022-08-06 10:02:04,687 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 129.27.206.5
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659772918644
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0279/
	 user: oovcharenko
2022-08-06 10:02:04,688 INFO cluster.YarnClientSchedulerBackend: Application application_1659444800769_0279 has started running.
2022-08-06 10:02:04,699 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46791.
2022-08-06 10:02:04,699 INFO netty.NettyBlockTransferService: Server created on tango.dm.isds.tugraz.at:46791
2022-08-06 10:02:04,701 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-08-06 10:02:04,708 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 46791, None)
2022-08-06 10:02:04,714 INFO storage.BlockManagerMasterEndpoint: Registering block manager tango.dm.isds.tugraz.at:46791 with 434.4 MiB RAM, BlockManagerId(driver, tango.dm.isds.tugraz.at, 46791, None)
2022-08-06 10:02:04,719 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 46791, None)
2022-08-06 10:02:04,721 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, tango.dm.isds.tugraz.at, 46791, None)
2022-08-06 10:02:04,938 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5f4608ad{/metrics/json,null,AVAILABLE,@Spark}
2022-08-06 10:02:04,947 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> charlie.dm.isds.tugraz.at, PROXY_URI_BASES -> http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0279), /proxy/application_1659444800769_0279
2022-08-06 10:02:05,865 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
2022-08-06 10:02:11,843 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.16:37508) with ID 2,  ResourceProfileId 0
2022-08-06 10:02:11,858 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.13:33632) with ID 3,  ResourceProfileId 0
2022-08-06 10:02:11,885 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.15:39324) with ID 1,  ResourceProfileId 0
2022-08-06 10:02:11,903 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2022-08-06 10:02:12,008 INFO storage.BlockManagerMasterEndpoint: Registering block manager oscar.dm.isds.tugraz.at:41835 with 59.8 GiB RAM, BlockManagerId(2, oscar.dm.isds.tugraz.at, 41835, None)
2022-08-06 10:02:12,024 INFO storage.BlockManagerMasterEndpoint: Registering block manager lima.dm.isds.tugraz.at:34347 with 59.8 GiB RAM, BlockManagerId(3, lima.dm.isds.tugraz.at, 34347, None)
2022-08-06 10:02:12,044 INFO storage.BlockManagerMasterEndpoint: Registering block manager november.dm.isds.tugraz.at:43565 with 59.8 GiB RAM, BlockManagerId(1, november.dm.isds.tugraz.at, 43565, None)
2022-08-06 10:02:12,116 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2022-08-06 10:02:12,119 INFO internal.SharedState: Warehouse path is 'file:/home/oovcharenko/benchmark/BS_OlgaOvcharenko/spark-warehouse'.
2022-08-06 10:02:12,136 INFO ui.ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-06 10:02:12,139 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@320d3de9{/SQL,null,AVAILABLE,@Spark}
2022-08-06 10:02:12,139 INFO ui.ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-06 10:02:12,140 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4b9311ee{/SQL/json,null,AVAILABLE,@Spark}
2022-08-06 10:02:12,141 INFO ui.ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-06 10:02:12,142 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@251057a5{/SQL/execution,null,AVAILABLE,@Spark}
2022-08-06 10:02:12,142 INFO ui.ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-06 10:02:12,143 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2d6bc38{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-08-06 10:02:12,144 INFO ui.ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-06 10:02:12,146 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6213ecd9{/static/sql,null,AVAILABLE,@Spark}
Created integer part 15.287964105606079
Created data 15.482213020324707
Num of rows 1638400000
Replacements state
REPLACEMENT start
REPLACEMENT Num repl 	3276800


Exception in thread "RemoteBlock-temp-file-clean-thread" Exception in thread "YARN application state monitor" java.lang.OutOfMemoryError: Java heap space
java.lang.OutOfMemoryError: Java heap space
2022-08-06 12:10:54,530 ERROR util.Utils: uncaught error in thread Spark Context Cleaner, stopping SparkContext
java.lang.OutOfMemoryError: Java heap space
2022-08-06 12:10:54,530 ERROR util.Utils: Uncaught exception in thread task-result-getter-0
java.lang.OutOfMemoryError: Java heap space
	at java.base/java.io.ObjectStreamClass.computeDefaultSUID(ObjectStreamClass.java:1878)
	at java.base/java.io.ObjectStreamClass$1.run(ObjectStreamClass.java:265)
	at java.base/java.io.ObjectStreamClass$1.run(ObjectStreamClass.java:263)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/java.io.ObjectStreamClass.getSerialVersionUID(ObjectStreamClass.java:262)
	at java.base/java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:684)
	at java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2012)
	at java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1862)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2169)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:493)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:451)
	at org.apache.spark.scheduler.DirectTaskResult.$anonfun$readExternal$2(TaskResult.scala:72)
	at org.apache.spark.scheduler.DirectTaskResult.$anonfun$readExternal$2$adapted(TaskResult.scala:71)
	at org.apache.spark.scheduler.DirectTaskResult$$Lambda$2631/0x00000008411f5040.apply(Unknown Source)
	at scala.collection.immutable.Range.foreach(Range.scala:158)
	at org.apache.spark.scheduler.DirectTaskResult.$anonfun$readExternal$1(TaskResult.scala:71)
	at org.apache.spark.scheduler.DirectTaskResult$$Lambda$2630/0x00000008411f4840.apply$mcV$sp(Unknown Source)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1428)
	at org.apache.spark.scheduler.DirectTaskResult.readExternal(TaskResult.scala:60)
	at java.base/java.io.ObjectInputStream.readExternalData(ObjectInputStream.java:2245)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2194)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:493)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:451)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:109)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:64)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$Lambda$2629/0x00000008411f3c40.apply$mcV$sp(Unknown Source)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2019)
2022-08-06 12:10:54,530 ERROR netty.Inbox: An error happened while processing message in the inbox for CoarseGrainedScheduler
java.lang.OutOfMemoryError: Java heap space
2022-08-06 12:10:55,190 ERROR util.Utils: throw uncaught fatal error in thread Spark Context Cleaner
java.lang.OutOfMemoryError: Java heap space
Exception in thread "Spark Context Cleaner" java.lang.OutOfMemoryError: Java heap space
Exception in thread "task-result-getter-0" java.lang.OutOfMemoryError: Java heap space
	at java.base/java.io.ObjectStreamClass.computeDefaultSUID(ObjectStreamClass.java:1878)
	at java.base/java.io.ObjectStreamClass$1.run(ObjectStreamClass.java:265)
	at java.base/java.io.ObjectStreamClass$1.run(ObjectStreamClass.java:263)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/java.io.ObjectStreamClass.getSerialVersionUID(ObjectStreamClass.java:262)
	at java.base/java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:684)
	at java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2012)
	at java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1862)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2169)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:493)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:451)
	at org.apache.spark.scheduler.DirectTaskResult.$anonfun$readExternal$2(TaskResult.scala:72)
	at org.apache.spark.scheduler.DirectTaskResult.$anonfun$readExternal$2$adapted(TaskResult.scala:71)
	at org.apache.spark.scheduler.DirectTaskResult$$Lambda$2631/0x00000008411f5040.apply(Unknown Source)
	at scala.collection.immutable.Range.foreach(Range.scala:158)
	at org.apache.spark.scheduler.DirectTaskResult.$anonfun$readExternal$1(TaskResult.scala:71)
	at org.apache.spark.scheduler.DirectTaskResult$$Lambda$2630/0x00000008411f4840.apply$mcV$sp(Unknown Source)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1428)
	at org.apache.spark.scheduler.DirectTaskResult.readExternal(TaskResult.scala:60)
	at java.base/java.io.ObjectInputStream.readExternalData(ObjectInputStream.java:2245)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2194)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:493)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:451)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:109)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:64)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$Lambda$2629/0x00000008411f3c40.apply$mcV$sp(Unknown Source)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2019)

Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread "stop-spark-context"

Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread "task-result-getter-2"

Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread "driver-heartbeater"

Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread "driver-revive-thread"

Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread "dispatcher-CoarseGrainedScheduler"

Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread "rpc-server-4-5"

Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread "rpc-server-4-1"

Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread "rpc-server-4-7"

Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread "heartbeat-receiver-event-loop-thread"
Exception in thread "rpc-boss-3-1" java.lang.OutOfMemoryError: Java heap space
Exception in thread "rpc-server-4-8" java.lang.OutOfMemoryError: Java heap space
