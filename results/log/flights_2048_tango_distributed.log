WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.
Error dist count [0, 0, 0, 911, 1558, 1100, 1351]
Original error count [   0    0    0  911 1558 1100 1351]
2022-08-04 07:10:06,862 INFO spark.SparkContext: Running Spark version 3.2.0
2022-08-04 07:10:06,955 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-08-04 07:10:07,096 INFO resource.ResourceUtils: ==============================================================
2022-08-04 07:10:07,096 INFO resource.ResourceUtils: No custom resources configured for spark.driver.
2022-08-04 07:10:07,096 INFO resource.ResourceUtils: ==============================================================
2022-08-04 07:10:07,097 INFO spark.SparkContext: Submitted application: DataGenerator_dirty_flights_2048.0
2022-08-04 07:10:07,124 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 102400, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-08-04 07:10:07,149 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks per executor
2022-08-04 07:10:07,151 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0
2022-08-04 07:10:07,241 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-04 07:10:07,241 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-04 07:10:07,241 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-04 07:10:07,242 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-04 07:10:07,242 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-04 07:10:07,567 INFO util.Utils: Successfully started service 'sparkDriver' on port 42717.
2022-08-04 07:10:07,604 INFO spark.SparkEnv: Registering MapOutputTracker
2022-08-04 07:10:07,644 INFO spark.SparkEnv: Registering BlockManagerMaster
2022-08-04 07:10:07,666 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-08-04 07:10:07,667 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-08-04 07:10:07,714 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2022-08-04 07:10:07,742 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-fa4f040a-2ba9-4f85-bce6-3cf5e02fa41f
2022-08-04 07:10:07,781 INFO memory.MemoryStore: MemoryStore started with capacity 434.4 MiB
2022-08-04 07:10:07,828 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2022-08-04 07:10:07,968 INFO util.log: Logging initialized @5631ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-08-04 07:10:08,046 INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-Ubuntu-0ubuntu1.20.04
2022-08-04 07:10:08,069 INFO server.Server: Started @5733ms
2022-08-04 07:10:08,114 INFO server.AbstractConnector: Started ServerConnector@181010f2{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-08-04 07:10:08,115 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2022-08-04 07:10:08,143 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5106d484{/jobs,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,146 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@dea2702{/jobs/json,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,147 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74b593d3{/jobs/job,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,151 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@66ce4889{/jobs/job/json,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,152 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6e80161e{/stages,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,153 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3fb749a{/stages/json,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,154 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@38c0d8fc{/stages/stage,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,157 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@27633acc{/stages/stage/json,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,158 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@502d7fc9{/stages/pool,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,159 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@c4d3bdb{/stages/pool/json,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,160 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3976611a{/storage,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,161 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@58d23d47{/storage/json,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,162 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2463622e{/storage/rdd,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,164 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@727f3c58{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,165 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e740bdb{/environment,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,166 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1e148034{/environment/json,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,167 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4aed8c5e{/executors,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,168 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@72dbc1da{/executors/json,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,169 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2baa7139{/executors/threadDump,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,171 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@68a64f31{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,182 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@17212e0{/static,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,183 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6a8beceb{/,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,184 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59d48630{/api,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,186 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@30c2ab63{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,187 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@212e1dff{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-08-04 07:10:08,189 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://tango.dm.isds.tugraz.at:4040
2022-08-04 07:10:08,547 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at charlie.dm.isds.tugraz.at/129.27.206.4:8032
2022-08-04 07:10:08,755 INFO yarn.Client: Requesting a new application from cluster with 9 NodeManagers
2022-08-04 07:10:09,279 INFO conf.Configuration: resource-types.xml not found
2022-08-04 07:10:09,279 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2022-08-04 07:10:09,293 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (122880 MB per container)
2022-08-04 07:10:09,294 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
2022-08-04 07:10:09,294 INFO yarn.Client: Setting up container launch context for our AM
2022-08-04 07:10:09,296 INFO yarn.Client: Setting up the launch environment for our AM container
2022-08-04 07:10:09,302 INFO yarn.Client: Preparing resources for our AM container
2022-08-04 07:10:09,923 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2022-08-04 07:10:12,408 INFO yarn.Client: Uploading resource file:/tmp/spark-5135a256-88fc-4221-93db-541ff45a33f2/__spark_libs__5418110888608228351.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0208/__spark_libs__5418110888608228351.zip
2022-08-04 07:10:15,138 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/pyspark.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0208/pyspark.zip
2022-08-04 07:10:16,261 INFO yarn.Client: Uploading resource file:/home/oovcharenko/spark-3.2.0-bin-hadoop3.2/python/lib/py4j-0.10.9.2-src.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0208/py4j-0.10.9.2-src.zip
2022-08-04 07:10:17,559 INFO yarn.Client: Uploading resource file:/tmp/spark-5135a256-88fc-4221-93db-541ff45a33f2/__spark_conf__4232965507673516258.zip -> hdfs://charlie.dm.isds.tugraz.at:9000/user/oovcharenko/.sparkStaging/application_1659444800769_0208/__spark_conf__.zip
2022-08-04 07:10:19,072 INFO spark.SecurityManager: Changing view acls to: oovcharenko
2022-08-04 07:10:19,072 INFO spark.SecurityManager: Changing modify acls to: oovcharenko
2022-08-04 07:10:19,072 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-04 07:10:19,072 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-04 07:10:19,072 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oovcharenko); groups with view permissions: Set(); users  with modify permissions: Set(oovcharenko); groups with modify permissions: Set()
2022-08-04 07:10:19,094 INFO yarn.Client: Submitting application application_1659444800769_0208 to ResourceManager
2022-08-04 07:10:19,150 INFO impl.YarnClientImpl: Submitted application application_1659444800769_0208
2022-08-04 07:10:20,153 INFO yarn.Client: Application report for application_1659444800769_0208 (state: ACCEPTED)
2022-08-04 07:10:20,157 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659589819123
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0208/
	 user: oovcharenko
2022-08-04 07:10:21,158 INFO yarn.Client: Application report for application_1659444800769_0208 (state: ACCEPTED)
2022-08-04 07:10:22,160 INFO yarn.Client: Application report for application_1659444800769_0208 (state: ACCEPTED)
2022-08-04 07:10:23,161 INFO yarn.Client: Application report for application_1659444800769_0208 (state: ACCEPTED)
2022-08-04 07:10:24,163 INFO yarn.Client: Application report for application_1659444800769_0208 (state: ACCEPTED)
2022-08-04 07:10:25,164 INFO yarn.Client: Application report for application_1659444800769_0208 (state: RUNNING)
2022-08-04 07:10:25,165 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 129.27.206.16
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1659589819123
	 final status: UNDEFINED
	 tracking URL: http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0208/
	 user: oovcharenko
2022-08-04 07:10:25,166 INFO cluster.YarnClientSchedulerBackend: Application application_1659444800769_0208 has started running.
2022-08-04 07:10:25,177 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40461.
2022-08-04 07:10:25,177 INFO netty.NettyBlockTransferService: Server created on tango.dm.isds.tugraz.at:40461
2022-08-04 07:10:25,179 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-08-04 07:10:25,186 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 40461, None)
2022-08-04 07:10:25,192 INFO storage.BlockManagerMasterEndpoint: Registering block manager tango.dm.isds.tugraz.at:40461 with 434.4 MiB RAM, BlockManagerId(driver, tango.dm.isds.tugraz.at, 40461, None)
2022-08-04 07:10:25,198 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, tango.dm.isds.tugraz.at, 40461, None)
2022-08-04 07:10:25,199 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, tango.dm.isds.tugraz.at, 40461, None)
2022-08-04 07:10:25,392 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> charlie.dm.isds.tugraz.at, PROXY_URI_BASES -> http://charlie.dm.isds.tugraz.at:8088/proxy/application_1659444800769_0208), /proxy/application_1659444800769_0208
2022-08-04 07:10:25,429 INFO ui.ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 07:10:25,431 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@42098a48{/metrics/json,null,AVAILABLE,@Spark}
2022-08-04 07:10:26,279 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
2022-08-04 07:10:31,704 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.15:47590) with ID 2,  ResourceProfileId 0
2022-08-04 07:10:31,874 INFO storage.BlockManagerMasterEndpoint: Registering block manager november.dm.isds.tugraz.at:40437 with 59.8 GiB RAM, BlockManagerId(2, november.dm.isds.tugraz.at, 40437, None)
2022-08-04 07:10:32,450 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.13:60504) with ID 1,  ResourceProfileId 0
2022-08-04 07:10:32,612 INFO storage.BlockManagerMasterEndpoint: Registering block manager lima.dm.isds.tugraz.at:40243 with 59.8 GiB RAM, BlockManagerId(1, lima.dm.isds.tugraz.at, 40243, None)
2022-08-04 07:10:32,770 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (129.27.206.5:45042) with ID 3,  ResourceProfileId 0
2022-08-04 07:10:32,785 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2022-08-04 07:10:32,933 INFO storage.BlockManagerMasterEndpoint: Registering block manager delta.dm.isds.tugraz.at:41805 with 59.8 GiB RAM, BlockManagerId(3, delta.dm.isds.tugraz.at, 41805, None)
2022-08-04 07:10:32,993 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2022-08-04 07:10:32,995 INFO internal.SharedState: Warehouse path is 'file:/home/oovcharenko/benchmark/BS_OlgaOvcharenko/spark-warehouse'.
2022-08-04 07:10:33,011 INFO ui.ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 07:10:33,014 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@39cb0015{/SQL,null,AVAILABLE,@Spark}
2022-08-04 07:10:33,014 INFO ui.ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 07:10:33,015 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2b9843e0{/SQL/json,null,AVAILABLE,@Spark}
2022-08-04 07:10:33,015 INFO ui.ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 07:10:33,017 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c5e84cd{/SQL/execution,null,AVAILABLE,@Spark}
2022-08-04 07:10:33,017 INFO ui.ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 07:10:33,018 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@21a870e7{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-08-04 07:10:33,019 INFO ui.ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2022-08-04 07:10:33,020 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1ab13750{/static/sql,null,AVAILABLE,@Spark}
Created integer part 10.3636794090271
Created data 10.537680625915527
Num of rows 4866048

SCHED_DEP_TIME
Set values
Random sample 2.0192668437957764
Create errors lists sample 3.607849359512329

ACT_DEP_TIME
Set values
Random sample 2.429546356201172
Create errors lists sample 5.008493900299072

SCHED_ARR_TIME
Set values
Random sample 2.054349422454834
Create errors lists sample 3.544168472290039

ACT_ARR_TIME
Set values
Random sample 2.189810037612915
Create errors lists sample 4.058955669403076
Create error DATAFRAME  0.3073387145996094
Create spark obj 0.3129231929779053
Set values after join, TOTAL 0.37759995460510254
Create error DATAFRAME  2.317868947982788
Create spark obj 2.3224973678588867
Set values after join, TOTAL 2.356506824493408
Create error DATAFRAME  0.2894723415374756
Create spark obj 0.2939305305480957
Set values after join, TOTAL 0.3273475170135498
Create error DATAFRAME  0.2385702133178711
Create spark obj 0.24323749542236328
Set values after join, TOTAL 0.27890467643737793
Replacements sched_dep_time
REPLACEMENT start
REPLACEMENT Num repl 	36864


REPLACEMENT Create replacement DATAFRAME  670.7098007202148
REPLACEMENT Create spark obj 670.7141172885895
REPLACEMENT all 670.7475817203522
Replacements act_dep_time
REPLACEMENT start
REPLACEMENT Num repl 	425984


REPLACEMENT Create replacement DATAFRAME  836.5321521759033
REPLACEMENT Create spark obj 836.5354678630829
REPLACEMENT all 836.5583307743073
Replacements sched_arr_time
REPLACEMENT start
REPLACEMENT Num repl 	40960


REPLACEMENT Create replacement DATAFRAME  945.3324432373047
REPLACEMENT Create spark obj 945.3361597061157
REPLACEMENT all 945.3599021434784
Replacements act_arr_time
REPLACEMENT start
REPLACEMENT Num repl 	139264


REPLACEMENT Create replacement DATAFRAME  1174.684775352478
REPLACEMENT Create spark obj 1174.6882922649384
REPLACEMENT all 1174.7112863063812
Swaps numerical done
Swaps str
Generated dataset
Save dataset: 6043.673207044601

Error distribution computation: 0.7589380741119385

Scale dataset: 37.56535744667053

Errors to scaled dataset: 3638.293473005295

Generated error distribution: 1415.0454361438751

--------------------------------------------------------
tuple_id
Mean original dirty: 	 1188.5
Mean generated dirty: 	 6.1825121354812955

Var original dirty: 	 470646.0
Var generated dirty: 	 8180.5132938596635

Q25 original dirty: 	 594.75
Q25 generated dirty: 	 1.0

INFO: Q25 differs from original dirty data

Q50 original dirty: 	 1188.5
Q50 generated dirty: 	 1.0

INFO: Q50 differs from original dirty data

Q75 original dirty: 	 1782.25
Q75 generated dirty: 	 1.0

INFO: Q75 differs from original dirty data

Min original dirty: 	 1
Min generated dirty: 	 1.0

Max original dirty: 	 2376
Max generated dirty: 	 2376.0

--------------------------------------------------------
--------------------------------------------------------
tuple_id
Distinct original dirty: 	 2376
Distinct original clean: 	 2376
Distinct estimated dirty (whole dataset): 	 4866048, distinct with ratio 	 4866048
Distinct estimated dirty (replicate + errors): 	 2376.0
Distinct generated dirty: 	 2093

--------------------------------------------------------
src
Distinct original dirty: 	 38
Distinct original clean: 	 38
Distinct estimated dirty (whole dataset): 	 71, distinct with ratio 	 71
Distinct estimated dirty (replicate + errors): 	 38.0
Distinct generated dirty: 	 29

--------------------------------------------------------
flight
Distinct original dirty: 	 100
Distinct original clean: 	 100
Distinct estimated dirty (whole dataset): 	 100, distinct with ratio 	 100
Distinct estimated dirty (replicate + errors): 	 100.0
Distinct generated dirty: 	 97

--------------------------------------------------------
sched_dep_time
Distinct original dirty: 	 138
Distinct original clean: 	 79
Distinct estimated dirty (whole dataset): 	 4665, distinct with ratio 	 4665
Distinct estimated dirty (replicate + errors): 	 6294.0
Distinct generated dirty: 	 4843

Replacements original dirty: 	 18
Replacements generated dirty: 	 32684

Traceback (most recent call last):
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/test_scale_up_distributed.py", line 23, in <module>
    generated_data = scale_modify.run_distributed(
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/scale_modify.py", line 206, in run_distributed
    compare_error_dist.compare_error_distributions_statistics_sp(
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/compare_error_dist.py", line 15, in compare_error_distributions_statistics_sp
    compare_distincts_sp(cols=cols, original=original, generated=generated)
  File "/home/oovcharenko/benchmark/BS_OlgaOvcharenko/compare_error_dist.py", line 270, in compare_distincts_sp
    assert round(original.distinct_replacements_count[c] * original.scaling_factor) * 0.9 <= \
AssertionError: In sched_dep_time changed replacements distribution, original - 36864, gen - 32684

real	185m41.545s
user	3m21.254s
sys	0m22.397s
